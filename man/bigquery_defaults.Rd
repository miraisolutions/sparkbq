% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/defaults.R
\name{bigquery_defaults}
\alias{bigquery_defaults}
\title{Google BigQuery Default Settings}
\usage{
bigquery_defaults(billingProjectId, gcsBucket, datasetLocation, type = NULL)
}
\arguments{
\item{billingProjectId}{Default Google Cloud Platform project ID for billing purposes.
This is the project on whose behalf to perform BigQuery operations.}

\item{gcsBucket}{Default Google Cloud Storage bucket used for temporary BigQuery files.
This should be the name of an existing storage bucket.}

\item{datasetLocation}{Default Google BigQuery dataset location ("EU" or "US").}

\item{type}{Default BigQuery import/export type to use. Options include "direct",
"parquet", "avro", "orc", "json" and "csv". If not set, it defaults to
\code{NULL}, meaning that the default spark-bigquery import/export mechanism
will be used (i.e. "direct"). Please note that only "direct" and "avro"
are supported for both importing and exporting. \cr
"csv" and "json" are not recommended due to their lack of type safety.

See the table below for supported type and import/export combinations.

\tabular{lcccccc}{
                                         \tab Direct \tab Parquet \tab Avro \tab ORC \tab JSON \tab CSV  \cr
  Import to Spark (export from BigQuery) \tab X      \tab         \tab X    \tab     \tab X    \tab X    \cr
  Export from Spark (import to BigQuery) \tab X      \tab X       \tab X    \tab X   \tab      \tab      \cr
}}
}
\value{
A \code{list} of set options with previous values.
}
\description{
Sets default values for several Google BigQuery related settings.
}
\references{
\url{https://github.com/miraisolutions/spark-bigquery}
\url{https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet}
\url{https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro}
\url{https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-orc}
\url{https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json}
\url{https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv}
}
\seealso{
\code{\link{spark_read_bigquery}}, \code{\link{spark_write_bigquery}},
\code{\link{default_billing_project_id}}, \code{\link{default_gcs_bucket}},
\code{\link{default_dataset_location}}
}
\keyword{connection}
\keyword{database,}
