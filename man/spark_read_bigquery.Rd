% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spark_read_bigquery.R
\name{spark_read_bigquery}
\alias{spark_read_bigquery}
\title{Reading data from Google BigQuery table}
\usage{
spark_read_bigquery(sc, tableOrQuery, projectId, datasetId, tableId, gcsBucket,
  datasetLocation)
}
\arguments{
\item{sc}{\code{spark_connection} provided by sparklyr}

\item{tableOrQuery}{either the name of a Google BigQuery table,
or an SQL query string
TODO: verify whether it is possible to specify as first line of the
      query \#legacySQL or \#standardSQL, and which flavor is the
      default one (I guess legacySQL)
      See: https://cloud.google.com/bigquery/docs/reference/legacy-sql
      and: https://cloud.google.com/bigquery/docs/reference/standard-sql/}

\item{projectId}{id of the project to be used}

\item{datasetId}{id of the dataset to be used for queries}

\item{tableId}{id of the Google BigQuery table to be used for queries}

\item{gcsBucket}{Google Cloud Storage bucket used for temporary files}

\item{datasetLocation}{geographical location of the dataset (for example "EU" for Europe)
This parameter can be found in the Google BigQuery web UI, under the "Dataset Details"}
}
\description{
This functions reads data stored in
a Google BigQuery table using Mirai Solution's spark-bigquery
datasource.
}
